{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic counting with OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOcnVXkZNXaj"
      },
      "source": [
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import logging\n",
        "import logging.handlers\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# without this some strange errors happen\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "random.seed(123)\n",
        "\n",
        "def init_logging(level=logging.INFO):\n",
        "    main_logger = logging.getLogger()\n",
        "    for hnd in main_logger.handlers:\n",
        "        main_logger.removeHandler(hnd)\n",
        "\n",
        "    formatter = logging.Formatter(\n",
        "        fmt='%(asctime)s.%(msecs)03d %(levelname)-8s [%(name)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    handler_stream = logging.StreamHandler(sys.stdout)\n",
        "    handler_stream.setFormatter(formatter)\n",
        "    main_logger.addHandler(handler_stream)\n",
        "    main_logger.setLevel(level)\n",
        "\n",
        "    return main_logger"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzAFeV0yeq4Y"
      },
      "source": [
        "def train_bg_subtractor(inst, cap, num=500):\n",
        "    '''\n",
        "        BG substractor need process some amount of frames to start giving result\n",
        "    '''\n",
        "    print ('Training BG Subtractor...')\n",
        "    i = 0\n",
        "    for frame in cap:\n",
        "        inst.apply(frame, None, 0.001)\n",
        "        i += 1\n",
        "        if i >= num:\n",
        "            return cap\n",
        "\n",
        "VIDEO_SOURCE = \"demo.mp4\"\n",
        "\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
        "        history=500, detectShadows=True)\n",
        "\n",
        "# Set up image source\n",
        "cap = skvideo.io.vreader(VIDEO_SOURCE)\n",
        "\n",
        "# skipping 500 frames to train bg subtractor\n",
        "train_bg_subtractor(bg_subtractor, cap, num=500)\n",
        "\n",
        "frame = next(cap)\n",
        "fg_mask = bg_subtractor.apply(frame, None, 0.001)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.imshow(fg_mask)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E6P7EEZfl7u"
      },
      "source": [
        "\n",
        "def filter_mask(img):\n",
        "    '''\n",
        "        This filters are hand-picked just based on visual tests\n",
        "    '''\n",
        "\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
        "\n",
        "    # Fill any small holes\n",
        "    closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "    # Remove noise\n",
        "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Dilate to merge adjacent blobs\n",
        "    dilation = cv2.dilate(opening, kernel, iterations=2)\n",
        "\n",
        "    return dilation\n",
        "\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
        "        history=500, detectShadows=True)\n",
        "\n",
        "cap = skvideo.io.vreader(VIDEO_SOURCE)\n",
        "\n",
        "train_bg_subtractor(bg_subtractor, cap, num=500)\n",
        "\n",
        "frame = next(cap)\n",
        "fg_mask = bg_subtractor.apply(frame, None, 0.001)\n",
        "fg_mask[fg_mask < 240] = 0\n",
        "fg_mask = filter_mask(fg_mask)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.imshow(fg_mask)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ_2lQtNgVNB"
      },
      "source": [
        "def get_centroid(x, y, w, h):\n",
        "    x1 = int(w / 2)\n",
        "    y1 = int(h / 2)\n",
        "\n",
        "    cx = x + x1\n",
        "    cy = y + y1\n",
        "\n",
        "    return (cx, cy)\n",
        "\n",
        "\n",
        "class ContourDetection:\n",
        "   \n",
        "   \n",
        "\n",
        "    def __init__(self, bg_subtractor, min_contour_width=35, min_contour_height=35, save_image=False, image_dir='images'):\n",
        "        super(ContourDetection, self).__init__()\n",
        "\n",
        "        self.bg_subtractor = bg_subtractor\n",
        "        self.min_contour_width = min_contour_width\n",
        "        self.min_contour_height = min_contour_height\n",
        "        self.save_image = save_image\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def filter_mask(self, img, a=None):\n",
        "       \n",
        "\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
        "\n",
        "        # Fill any small holes\n",
        "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "        # Remove noise\n",
        "        opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        # Dilate to merge adjacent blobs\n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2)\n",
        "\n",
        "        return dilation\n",
        "\n",
        "    def detect_vehicles(self, fg_mask):\n",
        "\n",
        "        matches = []\n",
        "\n",
        "        # finding external contours\n",
        "        contours, hierarchy = cv2.findContours(\n",
        "            fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n",
        "\n",
        "        for (i, contour) in enumerate(contours):\n",
        "            (x, y, w, h) = cv2.boundingRect(contour)\n",
        "            # On the exit, we add some filtering by height, width and add centroid.\n",
        "            contour_valid = (w >= self.min_contour_width) and (\n",
        "                h >= self.min_contour_height)\n",
        "\n",
        "            if not contour_valid:\n",
        "                continue\n",
        "\n",
        "            centroid = get_centroid(x, y, w, h)\n",
        "\n",
        "            matches.append(((x, y, w, h), centroid))\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def __call__(self, frame):\n",
        "        frame = frame.copy()\n",
        "\n",
        "        fg_mask = self.bg_subtractor.apply(frame, None, 0.001)\n",
        "        # just thresholding values\n",
        "        fg_mask[fg_mask < 240] = 0\n",
        "        fg_mask = self.filter_mask(fg_mask, 0)\n",
        "\n",
        "        return self.detect_vehicles(fg_mask)\n",
        "\n",
        "cd = ContourDetection(bg_subtractor)\n",
        "\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
        "        history=500, detectShadows=True)\n",
        "\n",
        "# Set up image source\n",
        "cap = skvideo.io.vreader(VIDEO_SOURCE)\n",
        "\n",
        "# skipping 500 frames to train bg subtractor\n",
        "train_bg_subtractor(bg_subtractor, cap, num=500)\n",
        "\n",
        "frame = next(cap)\n",
        "objects = cd(frame)\n",
        "\n",
        "print('Getting list of [((x,y,w,h), (xc,yc)), ...]')\n",
        "print(objects)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS-n0jQ2h5kT"
      },
      "source": [
        "\n",
        "class PipelineRunner(object):\n",
        "    \n",
        "\n",
        "    def __init__(self, pipeline=None, log_level=logging.INFO):\n",
        "        self.pipeline = pipeline or []\n",
        "        self.context = {}\n",
        "        self.log = logging.getLogger(self.__class__.__name__)\n",
        "        self.log.setLevel(log_level)\n",
        "        self.log_level = log_level\n",
        "        self.set_log_level()\n",
        "\n",
        "    def set_context(self, data):\n",
        "        self.context = data\n",
        "\n",
        "    def add(self, processor):\n",
        "        if not isinstance(processor, PipelineProcessor):\n",
        "            raise Exception(\n",
        "                'Processor should be an isinstance of PipelineProcessor.')\n",
        "        processor.log.setLevel(self.log_level)\n",
        "        self.pipeline.append(processor)\n",
        "\n",
        "    def remove(self, name):\n",
        "        for i, p in enumerate(self.pipeline):\n",
        "            if p.__class__.__name__ == name:\n",
        "                del self.pipeline[i]\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def set_log_level(self):\n",
        "        for p in self.pipeline:\n",
        "            p.log.setLevel(self.log_level)\n",
        "\n",
        "    def run(self):\n",
        "        for p in self.pipeline:\n",
        "            self.context = p(self.context)\n",
        "\n",
        "        self.log.debug(\"Frame #%d processed.\", self.context['frame_number'])\n",
        "\n",
        "        return self.context\n",
        "\n",
        "\n",
        "class PipelineProcessor(object):\n",
        "     \n",
        "\n",
        "    def __init__(self):\n",
        "        self.log = logging.getLogger(self.__class__.__name__)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPawBiwOiWNe"
      },
      "source": [
        "def save_frame(frame, file_name, flip=True):\n",
        "    # flip BGR to RGB\n",
        "    if flip:\n",
        "        cv2.imwrite(file_name, np.flip(frame, 2))\n",
        "    else:\n",
        "        cv2.imwrite(file_name, frame)\n",
        "\n",
        "class ContourDetection(PipelineProcessor):\n",
        "   \n",
        "\n",
        "    def __init__(self, bg_subtractor, min_contour_width=35, min_contour_height=35, save_image=False, image_dir='images'):\n",
        "        super(ContourDetection, self).__init__()\n",
        "\n",
        "        self.bg_subtractor = bg_subtractor\n",
        "        self.min_contour_width = min_contour_width\n",
        "        self.min_contour_height = min_contour_height\n",
        "        self.save_image = save_image\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def filter_mask(self, img, a=None):\n",
        "       \n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
        "\n",
        "        # Fill any small holes\n",
        "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "        # Remove noise\n",
        "        opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        # Dilate to merge adjacent blobs\n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2)\n",
        "\n",
        "        return dilation\n",
        "\n",
        "    def detect_vehicles(self, fg_mask, context):\n",
        "\n",
        "        matches = []\n",
        "\n",
        "        # finding external contours\n",
        "        contours, hierarchy = cv2.findContours(\n",
        "            fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n",
        "\n",
        "        for (i, contour) in enumerate(contours):\n",
        "            (x, y, w, h) = cv2.boundingRect(contour)\n",
        "            contour_valid = (w >= self.min_contour_width) and (\n",
        "                h >= self.min_contour_height)\n",
        "\n",
        "            if not contour_valid:\n",
        "                continue\n",
        "\n",
        "            centroid = get_centroid(x, y, w, h)\n",
        "\n",
        "            matches.append(((x, y, w, h), centroid))\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def __call__(self, context):\n",
        "        frame = context['frame'].copy()\n",
        "        frame_number = context['frame_number']\n",
        "\n",
        "        fg_mask = self.bg_subtractor.apply(frame, None, 0.001)\n",
        "        # just thresholding values\n",
        "        fg_mask[fg_mask < 240] = 0\n",
        "        fg_mask = self.filter_mask(fg_mask, frame_number)\n",
        "\n",
        "        if self.save_image:\n",
        "            save_frame(fg_mask, self.image_dir +\n",
        "                             \"/mask_%04d.png\" % frame_number, flip=False)\n",
        "\n",
        "        context['objects'] = self.detect_vehicles(fg_mask, context)\n",
        "        context['fg_mask'] = fg_mask\n",
        "\n",
        "        return context\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh3dhyf9iaKF"
      },
      "source": [
        "def distance(x, y, type='euclidian', x_weight=1.0, y_weight=1.0):\n",
        "    if type == 'euclidian':\n",
        "        return math.sqrt(float((x[0] - y[0])**2) / x_weight + float((x[1] - y[1])**2) / y_weight)\n",
        "\n",
        "\n",
        "class VehicleCounter(PipelineProcessor):\n",
        "  \n",
        "\n",
        "    def __init__(self, exit_masks=[], path_size=10, max_dst=30, x_weight=1.0, y_weight=1.0):\n",
        "        super(VehicleCounter, self).__init__()\n",
        "\n",
        "        self.exit_masks = exit_masks\n",
        "\n",
        "        self.vehicle_count = 0\n",
        "        self.path_size = path_size\n",
        "        self.pathes = []\n",
        "        self.max_dst = max_dst\n",
        "        self.x_weight = x_weight\n",
        "        self.y_weight = y_weight\n",
        "\n",
        "    def check_exit(self, point):\n",
        "        for exit_mask in self.exit_masks:\n",
        "            try:\n",
        "                if exit_mask[point[1]][point[0]] == 255:\n",
        "                    return True\n",
        "            except:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def __call__(self, context):\n",
        "        objects = context['objects']\n",
        "        context['exit_masks'] = self.exit_masks\n",
        "        context['pathes'] = self.pathes\n",
        "        context['vehicle_count'] = self.vehicle_count\n",
        "        if not objects:\n",
        "            return context\n",
        "\n",
        "        points = np.array(objects)[:, 0:2]\n",
        "        points = points.tolist()\n",
        "\n",
        "        if not self.pathes:\n",
        "            for match in points:\n",
        "                self.pathes.append([match])\n",
        "\n",
        "        else:\n",
        "            # points\n",
        "            new_pathes = []\n",
        "\n",
        "            for path in self.pathes:\n",
        "                _min = 999999\n",
        "                _match = None\n",
        "                for p in points:\n",
        "                    if len(path) == 1:\n",
        "                        d = distance(p[0], path[-1][0])\n",
        "                    else:\n",
        "                        xn = 2 * path[-1][0][0] - path[-2][0][0]\n",
        "                        yn = 2 * path[-1][0][1] - path[-2][0][1]\n",
        "                        d = distance(\n",
        "                            p[0], (xn, yn),\n",
        "                            x_weight=self.x_weight,\n",
        "                            y_weight=self.y_weight\n",
        "                        )\n",
        "\n",
        "                    if d < _min:\n",
        "                        _min = d\n",
        "                        _match = p\n",
        "\n",
        "                if _match and _min <= self.max_dst:\n",
        "                    points.remove(_match)\n",
        "                    path.append(_match)\n",
        "                    new_pathes.append(path)\n",
        "\n",
        "                # do not drop path if current frame has no matches\n",
        "                if _match is None:\n",
        "                    new_pathes.append(path)\n",
        "\n",
        "            self.pathes = new_pathes\n",
        "\n",
        "            # add new pathes\n",
        "            if len(points):\n",
        "                for p in points:\n",
        "                    # do not add points that already should be counted\n",
        "                    if self.check_exit(p[1]):\n",
        "                        continue\n",
        "                    self.pathes.append([p])\n",
        "\n",
        "        # save only last N points in path\n",
        "        for i, _ in enumerate(self.pathes):\n",
        "            self.pathes[i] = self.pathes[i][self.path_size * -1:]\n",
        "\n",
        "        # count vehicles and drop counted pathes:\n",
        "        new_pathes = []\n",
        "        for i, path in enumerate(self.pathes):\n",
        "            d = path[-2:]\n",
        "\n",
        "            if (\n",
        "                len(d) >= 2 and\n",
        "                not self.check_exit(d[0][1]) and\n",
        "                self.check_exit(d[1][1]) and\n",
        "                self.path_size <= len(path)\n",
        "            ):\n",
        "                self.vehicle_count += 1\n",
        "            else:\n",
        "                add = True\n",
        "                for p in path:\n",
        "                    if self.check_exit(p[1]):\n",
        "                        add = False\n",
        "                        break\n",
        "                if add:\n",
        "                    new_pathes.append(path)\n",
        "\n",
        "        self.pathes = new_pathes\n",
        "\n",
        "        context['pathes'] = self.pathes\n",
        "        context['objects'] = objects\n",
        "        context['vehicle_count'] = self.vehicle_count\n",
        "\n",
        "        self.log.debug('#VEHICLES FOUND: %s' % self.vehicle_count)\n",
        "\n",
        "        return context\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blYkPSNfi6iU"
      },
      "source": [
        "EXIT_PTS = np.array([\n",
        "    [[732, 720], [732, 590], [1280, 500], [1280, 720]],\n",
        "    [[0, 400], [645, 400], [645, 0], [0, 0]]\n",
        "])\n",
        "SHAPE = (720,1280)\n",
        "base = np.zeros(SHAPE + (3,), dtype='uint8')\n",
        "exit_mask = cv2.fillPoly(base, EXIT_PTS, (255, 255, 255))[:, :, 0]\n",
        "\n",
        "plt.imshow(base)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bKW1HyNjxal"
      },
      "source": [
        "class CsvWriter(PipelineProcessor):\n",
        "\n",
        "    def __init__(self, path, name, start_time=0, fps=15):\n",
        "        super(CsvWriter, self).__init__()\n",
        "\n",
        "        self.fp = open(os.path.join(path, name), 'w')\n",
        "        self.writer = csv.DictWriter(self.fp, fieldnames=['time', 'vehicles'])\n",
        "        self.writer.writeheader()\n",
        "        self.start_time = start_time\n",
        "        self.fps = fps\n",
        "        self.path = path\n",
        "        self.name = name\n",
        "        self.prev = None\n",
        "\n",
        "    def __call__(self, context):\n",
        "        frame_number = context['frame_number']\n",
        "        count = _count = context['vehicle_count']\n",
        "\n",
        "        if self.prev:\n",
        "            _count = count - self.prev\n",
        "\n",
        "        time = ((self.start_time + int(frame_number / self.fps)) * 100 \n",
        "                + int(100.0 / self.fps) * (frame_number % self.fps))\n",
        "        self.writer.writerow({'time': time, 'vehicles': _count})\n",
        "        self.prev = count\n",
        "\n",
        "        return context\n",
        "\n",
        "BOUNDING_BOX_COLOUR = (255, 192, 0)\n",
        "CENTROID_COLOUR = (255, 192, 0)\n",
        "CAR_COLOURS = [(255, 192, 0)]\n",
        "EXIT_COLOR = (66, 183, 42)\n",
        "\n",
        "class Visualizer(PipelineProcessor):\n",
        "\n",
        "    def __init__(self, save_image=True, image_dir='images'):\n",
        "        super(Visualizer, self).__init__()\n",
        "\n",
        "        self.save_image = save_image\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def check_exit(self, point, exit_masks=[]):\n",
        "        for exit_mask in exit_masks:\n",
        "            if exit_mask[point[1]][point[0]] == 255:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def draw_pathes(self, img, pathes):\n",
        "        if not img.any():\n",
        "            return\n",
        "\n",
        "        for i, path in enumerate(pathes):\n",
        "            path = np.array(path)[:, 1].tolist()\n",
        "            for point in path:\n",
        "                cv2.circle(img, point, 2, CAR_COLOURS[0], -1)\n",
        "                cv2.polylines(img, [np.int32(path)], False, CAR_COLOURS[0], 1)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def draw_boxes(self, img, pathes, exit_masks=[]):\n",
        "        for (i, match) in enumerate(pathes):\n",
        "\n",
        "            contour, centroid = match[-1][:2]\n",
        "            if self.check_exit(centroid, exit_masks):\n",
        "                continue\n",
        "\n",
        "            x, y, w, h = contour\n",
        "\n",
        "            cv2.rectangle(img, (x, y), (x + w - 1, y + h - 1),\n",
        "                          BOUNDING_BOX_COLOUR, 1)\n",
        "            cv2.circle(img, centroid, 2, CENTROID_COLOUR, -1)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def draw_ui(self, img, vehicle_count, exit_masks=[]):\n",
        "\n",
        "        # this just add green mask with opacity to the image\n",
        "        for exit_mask in exit_masks:\n",
        "            _img = np.zeros(img.shape, img.dtype)\n",
        "            _img[:, :] = EXIT_COLOR\n",
        "            mask = cv2.bitwise_and(_img, _img, mask=exit_mask)\n",
        "            cv2.addWeighted(mask, 1, img, 1, 0, img)\n",
        "\n",
        "        # drawing top block with counts\n",
        "        cv2.rectangle(img, (0, 0), (img.shape[1], 50), (0, 0, 0), cv2.FILLED)\n",
        "        cv2.putText(img, (\"Vehicles passed: {total} \".format(total=vehicle_count)), (30, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
        "        return img\n",
        "\n",
        "    def __call__(self, context):\n",
        "        frame = context['frame'].copy()\n",
        "        frame = np.ascontiguousarray(np.flip(frame, 2))\n",
        "        frame_number = context['frame_number']\n",
        "        pathes = context['pathes']\n",
        "        exit_masks = context['exit_masks']\n",
        "        vehicle_count = context['vehicle_count']\n",
        "\n",
        "        frame = self.draw_ui(frame, vehicle_count, exit_masks)\n",
        "        frame = self.draw_pathes(frame, pathes)\n",
        "        frame = self.draw_boxes(frame, pathes, exit_masks)\n",
        "        if self.save_image:\n",
        "            save_frame(frame, self.image_dir +\n",
        "                            \"/processed_%04d.png\" % frame_number)\n",
        "\n",
        "        context['frame'] = frame\n",
        "        return context"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JThMUvtONl-H"
      },
      "source": [
        "# build runner\n",
        "def main():\n",
        "    log = logging.getLogger(\"main\")\n",
        "\n",
        "    base = np.zeros(SHAPE + (3,), dtype='uint8')\n",
        "    exit_mask = cv2.fillPoly(base, EXIT_PTS, (255, 255, 255))[:, :, 0]\n",
        "\n",
        "    bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
        "        history=500, detectShadows=True)\n",
        "\n",
        "    pipeline = PipelineRunner(pipeline=[\n",
        "        ContourDetection(bg_subtractor=bg_subtractor,\n",
        "                         save_image=True, image_dir=IMAGE_DIR),\n",
        "        # we use y_weight == 2.0 because traffic are moving vertically on video\n",
        "        # use x_weight == 2.0 for horizontal.\n",
        "        VehicleCounter(exit_masks=[exit_mask], y_weight=2.0),\n",
        "        Visualizer(image_dir=IMAGE_DIR,save_image=False),\n",
        "        CsvWriter(path='./', name='report.csv')\n",
        "    ], log_level=logging.INFO)\n",
        "\n",
        "    # Set up image source\n",
        "    cap = skvideo.io.vreader(VIDEO_SOURCE)\n",
        "\n",
        "    # skipping 500 frames to train bg subtractor\n",
        "    train_bg_subtractor(bg_subtractor, cap, num=500)\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
        "    writer = cv2.VideoWriter(VIDEO_OUT, fourcc, 25, (SHAPE[1], SHAPE[0]), True)\n",
        "\n",
        "    frame_number = -1\n",
        "    for frame in cap:\n",
        "        if not frame.any():\n",
        "            log.error(\"Frame capture failed, stopping...\")\n",
        "            break\n",
        "\n",
        "        frame_number += 1\n",
        "        log.info(\"Frame #%s\" % frame_number)\n",
        "\n",
        "        pipeline.set_context({\n",
        "            'frame': frame,\n",
        "            'frame_number': frame_number,\n",
        "        })\n",
        "        ctx = pipeline.run()\n",
        "        writer.write(ctx['frame'])\n",
        "\n",
        "        if frame_number > PARSE_FRAMES:\n",
        "            break\n",
        "    writer.release()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7OK75rXNpBa"
      },
      "source": [
        "IMAGE_DIR = \"./out\"\n",
        "VIDEO_SOURCE = \"demo.mp4\"\n",
        "VIDEO_OUT = \"final.mp4\"\n",
        "PARSE_FRAMES = 15*25\n",
        "SHAPE = (720, 1280)  # HxW\n",
        "EXIT_PTS = np.array([\n",
        "    [[732, 720], [732, 590], [1280, 500], [1280, 720]],\n",
        "    [[0, 400], [645, 400], [645, 0], [0, 0]]\n",
        "])\n",
        "# ============================================================================\n",
        "\n",
        "log = init_logging()\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbofi3UAWGgj"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('final.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}